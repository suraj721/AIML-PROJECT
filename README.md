ğŸ“š Research Topic Analysis System



A traditional NLP-based research analysis system for academic documents (e.g., arXiv papers).
This project implements a classical Natural Language Processing and Machine Learning pipeline to analyze research documents without using Large Language Models (LLMs) or agentic AI systems.

ğŸš€ Project Overview

Researchers often need a quick analytical overview of a research domain but face difficulty when reviewing multiple academic papers.

This system automates research document analysis by:

Extracting key terms

Identifying latent topics

Clustering similar documents

Generating extractive summaries

Providing clustering evaluation metrics

All using interpretable statistical NLP techniques.

ğŸ§  Key Features

ğŸ“„ Upload multiple .txt or .pdf research papers

ğŸ” TF-IDF based key term extraction

ğŸ§© Topic modeling using Non-negative Matrix Factorization (NMF)

ğŸ“Š Document clustering using KMeans

âœ‚ Extractive summarization using sentence-level TF-IDF scoring

ğŸ“ˆ Silhouette score for clustering evaluation

ğŸŒ Interactive Streamlit web interface

ğŸ— System Architecture

The system follows a structured NLP pipeline:

Document Input

Research keywords

Uploaded TXT/PDF files

Text Preprocessing

Tokenization

Lowercasing

Stop-word removal

Lemmatization

Sentence segmentation

Feature Extraction

TF-IDF vectorization

Analysis

Topic modeling (NMF)

Document clustering (KMeans)

Summarization

TF-IDF-based sentence ranking

Output

Key terms

Topic clusters

Extractive summaries

Evaluation metrics

ğŸ“‚ Project Structure

research_topic_analysis/
â”‚
â”œâ”€â”€ app.py                # Streamlit user interface
â”œâ”€â”€ nlp_pipeline.py       # Core NLP & ML processing logic
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone <your-repo-link>
cd research_topic_analysis
2ï¸âƒ£ Create Virtual Environment
python -m venv .venv
source .venv/bin/activate      # Windows: .venv\Scripts\activate
3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
4ï¸âƒ£ Download NLP Models
python -m spacy download en_core_web_sm
python -m nltk.downloader punkt stopwords wordnet
â–¶ï¸ Run the Application
streamlit run app.py

Open the local URL (typically http://localhost:8501) in your browser.

ğŸ“Š Core Algorithms Used
Component	Technique
Feature Extraction	TF-IDF
Topic Modeling	NMF
Clustering	KMeans
Summarization	Sentence-level TF-IDF scoring
Evaluation	Silhouette Score
âš ï¸ Limitations

While effective and interpretable, traditional NLP approaches have limitations:

No semantic understanding of context

Ignores word order

Sensitive to preprocessing decisions

Requires manual topic selection

Limited generalization across domains

No autonomous reasoning or external knowledge retrieval

These limitations highlight opportunities for future integration of embedding-based models and intelligent workflows.

ğŸ”® Future Enhancements

Replace sparse TF-IDF with dense semantic embeddings

Add visualization dashboards for topic distributions

Improve summarization using hybrid statistical methods

Integrate intelligent retrieval mechanisms

Deploy publicly on cloud platforms

ğŸ›  Technologies Used

Python

Streamlit

scikit-learn

spaCy

NLTK

ğŸ“Œ License

This project is intended for academic and educational purposes.
